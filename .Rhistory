# Plot ROC curve
par(pty="s")
plot(roc_obj, main = paste(model_name, " ROC Curve", sep = ""), col = "blue", legacy.axes = TRUE, print.auc = TRUE)
source("~/DS2023/model.R")
importance <- varImp(Training_model)$importance
importance_df <- data.frame(Feature = row.names(importance), Importance = importance[, "Overall"])
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]
plot <- ggplot(importance_df, aes(x = Feature, y = Importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Feature Importance", x = "Feature", y = "Importance")
# Rotate x-axis labels if needed
plot + theme(axis.text.x = element_text(angle = 45, hjust = 1))
importance_df <- data.frame(Feature = row.names(importance), Importance = importance[, "Overall"])
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]
plot <- ggplot(importance_df, aes(x = Feature, y = Importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Feature Importance", x = "Feature", y = "Importance")
# Rotate x-axis labels if needed
plot + theme(axis.text.x = element_text(angle = 45, hjust = 1))
importance <- varImp(Training_model)$importance
importance <- importance[order(importance, decreasing = TRUE), ]
ggplot(importance, aes(x = rownames(importance), y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Feature Importance", x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
library(tidyverse)
library(caret)
library('e1071')
library(rpart)
library(ggplot2)
# library('yardstick')
# Load the feature.R file
source("feature.R")
train_data <- read_csv("Titanic/train.csv")
preprocess_train_data <- preprocess_data(train_data, "training")
test_data <- read_csv("Titanic/test.csv")
preprocess_test_data <- preprocess_data(test_data, "test")
model_name <- "Logistic regression"
train_data <- preprocess_train_data
# Set up the trainControl object for 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5, savePredictions = "all", classProbs = TRUE)
if(model_name == "Logistic regression"){
Training_model <- train(Survived ~ ., data = train_data, method = "glm", trControl = ctrl, family = "binomial")
} else if(model_name == "K nearest neighbors"){
Training_model <- train(Survived ~ ., data = train_data, method = "knn", trControl = ctrl, preProcess = c("center", "scale"),tuneLength = 3)
} else if(model_name == "SVC Linear"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "svmLinear", trControl = ctrl, scale = FALSE)
} else if(model_name == "SVC RBF"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "svmRadial", trControl = ctrl, scale = FALSE)
} else if(model_name == "Gaussian Naive Bayes"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "naiveBayes", trControl = ctrl)
} else if(model_name == "Decision Tree"){
Training_model <- train(Survived~., data = train_data, method = 'rpart', trControl = ctrl)
} else if(model_name == "Random Forest Classifier"){
Training_model <- train(Survived~., data = train_data, method = 'rf', trControl = ctrl)
}
# Predict on the training set
res_predictions <- predict(Training_model, newdata = train_data)
res_accuracy <- sum(res_predictions == train_data$Survived) / nrow(train_data)
res_cm <- table(res_predictions, train_data$Survived)
# Compute additional metrics
res_confusion <- confusionMatrix(res_predictions, train_data$Survived)
res_f1 <- res_confusion$byClass["F1"]
res_precision <- res_confusion$byClass["Pos Pred Value"]
res_recall <- res_confusion$byClass["Sensitivity"]
# Compute ROC AUC value
res_predictions_prob <- predict(Training_model, newdata = train_data, type = "prob")[, 2]
roc_obj <- roc(train_data$Survived, res_predictions_prob)
res_auc <- roc_obj$auc
importance <- varImp(Training_model)$importance
str(importance)
importance <- importance[order(importance$Overall, decreasing = TRUE), ]
importance_df <- as.data.frame(importance)
ggplot(importance_df, aes(x = rownames(importance_df), y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
importance <- varImp(Training_model)$importance
importance <- importance[order(importance$Overall, decreasing = TRUE), ]
importance_df <- as.data.frame(importance)
ggplot(importance_df, aes(x = rownames(importance_df), y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(importance_df, aes(x = rownames(importance_df), y = importance$Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("~/DS2023/model.R")
source("~/DS2023/model.R")
library(tidyverse)
library(caret)
library('e1071')
library(rpart)
library(ggplot2)
# library('yardstick')
# Load the feature.R file
source("feature.R")
train_data <- read_csv("Titanic/train.csv")
preprocess_train_data <- preprocess_data(train_data, "training")
test_data <- read_csv("Titanic/test.csv")
preprocess_test_data <- preprocess_data(test_data, "test")
model_name <- "Logistic regression"
train_data <- preprocess_train_data
# Set up the trainControl object for 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5, savePredictions = "all", classProbs = TRUE)
if(model_name == "Logistic regression"){
Training_model <- train(Survived ~ ., data = train_data, method = "glm", trControl = ctrl, family = "binomial")
} else if(model_name == "K nearest neighbors"){
Training_model <- train(Survived ~ ., data = train_data, method = "knn", trControl = ctrl, preProcess = c("center", "scale"),tuneLength = 3)
} else if(model_name == "SVC Linear"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "svmLinear", trControl = ctrl, scale = FALSE)
} else if(model_name == "SVC RBF"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "svmRadial", trControl = ctrl, scale = FALSE)
} else if(model_name == "Gaussian Naive Bayes"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "naiveBayes", trControl = ctrl)
} else if(model_name == "Decision Tree"){
Training_model <- train(Survived~., data = train_data, method = 'rpart', trControl = ctrl)
} else if(model_name == "Random Forest Classifier"){
Training_model <- train(Survived~., data = train_data, method = 'rf', trControl = ctrl)
}
# Predict on the training set
res_predictions <- predict(Training_model, newdata = train_data)
res_accuracy <- sum(res_predictions == train_data$Survived) / nrow(train_data)
res_cm <- table(res_predictions, train_data$Survived)
# Compute additional metrics
res_confusion <- confusionMatrix(res_predictions, train_data$Survived)
res_f1 <- res_confusion$byClass["F1"]
res_precision <- res_confusion$byClass["Pos Pred Value"]
res_recall <- res_confusion$byClass["Sensitivity"]
# Compute ROC AUC value
res_predictions_prob <- predict(Training_model, newdata = train_data, type = "prob")[, 2]
roc_obj <- roc(train_data$Survived, res_predictions_prob)
res_auc <- roc_obj$auc
importance <- varImp(Training_model)$importance
importance <- importance[order(importance$Overall, decreasing = TRUE), ]
importance_df <- as.data.frame(importance)
ggplot(importance_df, aes(x = rownames(importance_df), y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("~/DS2023/model.R")
ggplot(importance_df, aes(x = rownames(importance_df), y = importance$Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
str(importance)
ggplot(importance_df, aes(x = rownames(importance_df)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Print the results
message(sprintf("======= %s Model =======", model_name))
ggplot(importance_df, aes(x = rownames(importance_df))) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
# Compute ROC AUC value
res_predictions_prob <- predict(Training_model, newdata = train_data, type = "prob")[, 2]
roc_obj <- roc(train_data$Survived, res_predictions_prob)
res_auc <- roc_obj$auc
library(tidyverse)
library(caret)
library('e1071')
library(rpart)
library(ggplot2)
# library('yardstick')
# Load the feature.R file
source("feature.R")
train_data <- read_csv("Titanic/train.csv")
preprocess_train_data <- preprocess_data(train_data, "training")
test_data <- read_csv("Titanic/test.csv")
preprocess_test_data <- preprocess_data(test_data, "test")
model_name <- "Logistic regression"
train_data <- preprocess_train_data
# Set up the trainControl object for 5-fold cross-validation
ctrl <- trainControl(method = "cv", number = 5, savePredictions = "all", classProbs = TRUE)
if(model_name == "Logistic regression"){
Training_model <- train(Survived ~ ., data = train_data, method = "glm", trControl = ctrl, family = "binomial")
} else if(model_name == "K nearest neighbors"){
Training_model <- train(Survived ~ ., data = train_data, method = "knn", trControl = ctrl, preProcess = c("center", "scale"),tuneLength = 3)
} else if(model_name == "SVC Linear"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "svmLinear", trControl = ctrl, scale = FALSE)
} else if(model_name == "SVC RBF"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "svmRadial", trControl = ctrl, scale = FALSE)
} else if(model_name == "Gaussian Naive Bayes"){
Training_model <- train(Survived ~ ., data = train_data, kernel = "naiveBayes", trControl = ctrl)
} else if(model_name == "Decision Tree"){
Training_model <- train(Survived~., data = train_data, method = 'rpart', trControl = ctrl)
} else if(model_name == "Random Forest Classifier"){
Training_model <- train(Survived~., data = train_data, method = 'rf', trControl = ctrl)
}
# Predict on the training set
res_predictions <- predict(Training_model, newdata = train_data)
res_accuracy <- sum(res_predictions == train_data$Survived) / nrow(train_data)
res_cm <- table(res_predictions, train_data$Survived)
# Compute additional metrics
res_confusion <- confusionMatrix(res_predictions, train_data$Survived)
res_f1 <- res_confusion$byClass["F1"]
res_precision <- res_confusion$byClass["Pos Pred Value"]
res_recall <- res_confusion$byClass["Sensitivity"]
# Compute ROC AUC value
res_predictions_prob <- predict(Training_model, newdata = train_data, type = "prob")[, 2]
roc_obj <- roc(train_data$Survived, res_predictions_prob)
res_auc <- roc_obj$auc
importance <- varImp(Training_model)$importance
str(importance)
importance <- importance[order(importance$Overall, decreasing = TRUE), ]
importance_df <- as.data.frame(importance)
ggplot(importance_df, aes(x = rownames(importance_df), y = importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("~/DS2023/model.R")
source("~/DS2023/model.R")
ggplot(importance_df, aes(x = rownames(importance_df), y = importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_x_discrete(labels = rownames(importance_df))
View(importance_df)
ggplot(importance, aes(x = rownames(importance_df), y = importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_x_discrete(labels = rownames(importance_df))
importance <- varImp(Training_model)$importance
importance <- importance[order(importance$Overall, decreasing = TRUE), ]
importance <- varImp(Training_model)$importance
(importance)
importance <- importance[order(importance$Overall, decreasing = TRUE), ]
(importance)
importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE]
(importance)
importance <- varImp(Training_model)$importance
(importance)
importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE]
(importance)
importance$Feature <- rownames(importance)
importance_df <- as.data.frame(importance)
ggplot(importance_df, aes(x = rownames(importance_df), y = importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_x_discrete(labels = rownames(importance_df))
# ggplot(importance_df, aes(x = rownames(importance_df), y = importance)) +
#   geom_bar(stat = "identity", fill = "steelblue") +
#   labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#   scale_x_discrete(labels = rownames(importance_df))
ggplot(importance_df, aes(x = Feature, y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
(importance <- varImp(Training_model)$importance)
(importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE])
(importance$Feature <- rownames(importance))
(importance_df <- as.data.frame(importance))
# ggplot(importance_df, aes(x = rownames(importance_df), y = importance)) +
#   geom_bar(stat = "identity", fill = "steelblue") +
#   labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#   scale_x_discrete(labels = rownames(importance_df))
ggplot(importance_df, aes(x = Feature, y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
(importance <- varImp(Training_model)$importance)
(importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE])
(importance$Feature <- rownames(importance))
(importance_df <- as.data.frame(importance))
# ggplot(importance_df, aes(x = rownames(importance_df), y = importance)) +
#   geom_bar(stat = "identity", fill = "steelblue") +
#   labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#   scale_x_discrete(labels = rownames(importance_df))
ggplot(importance_df, aes(x = Feature, y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
(importance <- varImp(Training_model)$importance)
(importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE])
(importance$Feature <- rownames(importance))
(importance_df <- as.data.frame(importance))
(importance_df$Feature <- factor(importance_df$Feature, levels = importance_df$Feature))
ggplot(importance_df, aes(x = Feature, y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
source("~/DS2023/model.R")
library(dplyr)
importance_df <- importance_df %>%
rename(Feature = ifelse(Feature == "Sex_factors", "Sex", Feature))
source("~/DS2023/model.R")
source("~/DS2023/model.R")
(importance <- varImp(Training_model)$importance)
# Compute ROC AUC value
res_predictions_prob <- predict(Training_model, newdata = train_data, type = "prob")[, 2]
(importance <- varImp(Training_model)$importance)
(importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE])
(importance$Feature <- rownames(importance))
(importance_df <- as.data.frame(importance))
(importance_df$Feature <- factor(importance_df$Feature, levels = importance_df$Feature))
# Rename the "Sex_factors" feature to "Sex"
importance_df <- importance_df %>%
mutate(Feature = ifelse(Feature == "Sex_factors", "Sex", Feature))
ggplot(importance_df, aes(x = Feature, y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
(importance <- varImp(Training_model)$importance)
# Rename the "Sex_factors" feature to "Sex"
importance$Feature <- ifelse(importance$Feature == "Sex_factors", "Sex", importance$Feature)
(importance <- varImp(Training_model)$importance)
(importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE])
# Rename the "Sex_factors" feature to "Sex"
(importance <- importance %>% mutate(Feature = ifelse(Feature == "Sex_factors", "Sex", Feature)))
(importance <- varImp(Training_model)$importance)
(importance <- importance[order(importance$Overall, decreasing = TRUE), , drop = FALSE])
(importance$Feature <- rownames(importance))
# Rename the "Sex_factors" feature to "Sex"
importance$Feature <- ifelse(importance$Feature == "Sex_factors", "Sex", importance$Feature)
(importance_df <- as.data.frame(importance))
importance$Feature <- ifelse(importance$Feature == "Embarked_factors", "Embarked", importance$Feature)
(importance_df <- as.data.frame(importance))
(importance_df$Feature <- factor(importance_df$Feature, levels = importance_df$Feature))
ggplot(importance_df, aes(x = Feature, y = Overall)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = paste(model_name, " Feature Importance", sep = ""), x = "Feature", y = "Importance") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
shiny::runApp('demo2')
runApp('demo2')
runApp('demo2')
source("~/DS2023/model.R")
source("~/DS2023/model.R")
# model_list <- c("Logistic regression","K nearest neighbors","SVC Linear","SVC RBF","Gaussian Naive Bayes","Decision Tree","Random Forest Classifier")
model_list <- c("Logistic regression")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
source("~/DS2023/model.R")
runApp('demo2')
runApp('demo2')
runApp('demo2')
runApp('demo2')
runApp('demo2')
runApp('demo2')
runApp('demo2')
runApp('demo2')
source("~/DS2023/model.R")
runApp('demo2')
source("~/DS2023/demo2/app.R")
source("~/DS2023/demo2/app.R")
setwd("~/DS2023/demo2")
source("~/DS2023/demo2/app.R")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("shinyspinner")
install.packages("shinycssloaders")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
runApp('test.R')
source("~/DS2023/demo2/test.R")
source("~/DS2023/demo2/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
install.packages(audio)
source("~/DS2023/test.R")
source("~/DS2023/test.R")
setwd("~/DS2023")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
runApp('test.R')
runApp('test.R')
source("~/DS2023/test.R")
source("~/DS2023/test.R")
library(audio)
# Specify the path to your MP3 file
mp3_file <- "ready.mp3"
# Play the audio
# system2("afplay", mp3_file)  # macOS
# system2("aplay", mp3_file)  # Linux
system2("cmdmp3", mp3_file)  # Windows (requires cmdmp3 utility)
source("~/DS2023/test.R")
source("~/DS2023/test.R")
setwd("~/DS2023")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
source("~/DS2023/test.R")
runApp('test.R')
runApp('test.R')
runApp('test.R')
source("~/DS2023/test.R")
source("~/DS2023/test.R")
